Last year, I intensely started using AI (LLM) tools and caught a terrible wave of sadness and melancholy after 5–6 months of use.

For me, the most difficult thing wasn’t that an LLM could write code in general, but the realization that, in fact, it’s not that important. A much more significant abstract question arose: why even write it if everything could change so quickly tomorrow that you wouldn’t even blink?

After feeling down and literally being sick of it, and wandering through bookstores, I stumbled upon an interesting book — “The Art of Excellent Products: Enchanting Customers with Premium Brand Experiences” by Riccardo Illy. And this book resonated so deeply that I understood how to resolve (for the time being) the moral dilemma with AI code, when you don’t write the code yourself, but AI does — through ethical principles.

In my opinion, ethical principles offer three possibilities:

1. Limitations or focus — by establishing principles, you can focus only on what is truly important and discard/deprioritize what does not align with these principles.

2. Flexibility in decision-making — knowing the limitations and having an ethical focus, you can, if necessary, make responsible decisions faster, but without sacrificing what is ethically important for the company/product.

3. Trust — having limitations in the form of chosen ethical principles, the values of the product/company can become more resilient to crises — which in the end can lead to more trust in the product for the end user. In theory :) Therefore, since the beginning of the year, I have started thinking about principles/values and trying to understand which ones are suitable — and why.

So I stepped away from digital to write by hand in a notebook. I’ve divided them into several groups, since I think they may change from the type of purpose.

I choose: Applications, Games, Personal Principles

For example for apps I came to:
— Convenience
— Simplicity
— Safety
— Longevity
— Usefulness

For games (since it’s my hobby, it a little different):
— Usefulness
— Creativity
— Fun
— Challenge

I feel they will change over time, but for a start it is enough.
Currently (May), the 5th month of testing — and I can honestly say that it has become much easier to focus on the problem and the solution than before. I am sure that a lot will change with the development of AI — but it seems like this could become a bridge for working with it from a moral and ethical standpoint (especially when you need to negotiate/choose between faster and better).

I hope this post inspires and proves useful in some way :-)
Please share your thoughts in the comments :-) this will help make this thread visible to others and will be great support and motivation :-)

Thank you for your time and have a good day!
